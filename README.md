# Oral Disease Detection Model

## Model Overview
This repository hosts the training pipeline for a production-grade Oral Disease Detection system. The model is built on the Faster R-CNN architecture (ResNet-50 backbone) and is designed to detect and classify dental abnormalities from standard photographic inputs.

## Training Configuration
- **Architecture:** Faster R-CNN (ResNet-50-FPN)
- **Training Strategy:** Full Dataset Training (No Validation Split / K-Folds)
- **Epochs:** 50
- **Optimization:** SGD (Learning Rate: 0.005, Momentum: 0.9)
- **Class Handling:** 20-class capacity buffer to ensure scalability

## Usage
**Do not manually populate the `raw_data/` directory.** This directory is automatically generated by the data processing pipeline to ensure consistent formatting and file integrity.

1. **Build the Dataset:** Follow the **Setup Instructions** below to download sources and generate the training data.
2. **Submit Job:** Once the data pipeline is complete, submit the training job via SLURM:
   ```bash
   sbatch submit_job.sh
   ```
3. **Monitor:** Track progress in the logs:
   ```bash
   tail -f logs/training_run_log.txt
   ```

## Setup Instructions
To reproduce the dataset creation and training pipeline from scratch, execute the following commands in order:

### 1. Environment Setup
```bash
python -m venv venv
# Activate venv (source venv/bin/activate OR venv\Scripts\activate on Windows)
pip install -r requirements.txt
```

### 2. Data Acquisition
Before running any scripts, you must manually download the required datasets listed in the **Datasets** section below.
1. Download the zip files from the provided Roboflow and Zenodo links.
2. Extract the contents of each dataset into the `downloads/` directory (or the specific input folder expected by `load_datasets.py`).

### 3. Data Pipeline Execution
Once the raw datasets are in place, run the processing scripts in this exact order:

* **Step 1**
  Validates downloaded files and organizes them for processing.
  ```bash
  python load_datasets.py
  ```

* **Step 2**
  Removes invalid annotations, maps class labels (e.g., 'caries' -> Class 1), and cleans metadata.
  ```bash
  python filter_classes.py
  ```

* **Step 3**
  Builds the final `raw_data/` directory structure required by the model.
  ```bash
  python build.py
  ```

* **Step 4**
  Scans `raw_data/` and generates the `final_train_list.txt` master file.
  ```bash
  python create_dataset.py
  ```

## Datasets
The model is trained on a composite dataset aggregating approximately 6,600 images from the following specific sources:

1. **ORAL DETECTOR (Roboflow Universe)**
   * **Source:** [https://universe.roboflow.com/clients-mpvn2/oral-detector/dataset/3](https://universe.roboflow.com/clients-mpvn2/oral-detector/dataset/3)
   * **Credits:** User `clients-mpvn2` on Roboflow.
   * **Contribution:** Provided 4,131 images covering multiple disease classes (Gingivitis, Calculus, Ulcers, etc.).

2. **Annotated Intraoral Image Dataset for Dental Caries Detection (Zenodo)**
   * **Source:** [https://zenodo.org/records/14827784](https://zenodo.org/records/14827784)
   * **Authors:** Ahmed, Syed Muhammad Faizan; Ghori, Huzaifa; et al.
   * **DOI:** 10.5281/zenodo.14827784
   * **Contribution:** The primary source for the 'Caries' specific data subset.

3. **Healthy Teeth (Roboflow Universe)**
   * **Source:** [https://universe.roboflow.com/sultan-qyobm/healthy-teeth-hgddf/dataset/1](https://universe.roboflow.com/sultan-qyobm/healthy-teeth-hgddf/dataset/1)
   * **Credits:** User `sultan-qyobm` on Roboflow.
   * **Contribution:** Provided 235 healthy control images to prevent false positives.

## Logging & Auditing
The data processing scripts automatically generate execution logs to track data integrity:
- `logs/cleaning_log.txt`: Generated by `filter_classes.py`. Tracks class remapping and ghost label removal.
- `logs/build_log.txt`: Generated by `build.py`. Records extraction counts and file origins.
- `logs/dataset_creation_log.txt`: Generated by `create_dataset.py`. Tracks the final count of valid images added to the master training list.
- `logs/training_run_log.txt`: Generated by `train_pytorch.py`. Records loss metrics, epoch progress, and runtime errors during the training job.